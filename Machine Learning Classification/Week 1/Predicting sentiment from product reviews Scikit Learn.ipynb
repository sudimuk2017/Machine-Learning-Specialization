{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dtype_dict = {'name':str, 'review':str, 'rating': int}\n",
    "amazon = pd.read_csv('amazon_baby.csv', dtype = dtype_dict)\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform text cleaning\n",
    "We start by removing punctuation, so that words \"cake.\" and \"cake!\" are counted as the same word.\n",
    "\n",
    " *   Write a function remove_punctuation that strips punctuation from a line of text\n",
    " *   Apply this function to every element in the review column of products, and save the result to a new column review_clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT. Make sure to fill n/a values in the review column with empty strings (if applicable). The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the review columns as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = amazon.fillna({'review':''}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "      <td>These flannel wipes are OK but in my opinion n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  These flannel wipes are OK, but in my opinion ...       3   \n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "\n",
       "                                        review_clean  \n",
       "0  These flannel wipes are OK but in my opinion n...  \n",
       "1  it came early and was not disappointed i love ...  \n",
       "2  Very soft and comfortable and warmer than it l...  \n",
       "3  This is a product well worth the purchase  I h...  \n",
       "4  All of my kids have cried nonstop when I tried...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator) \n",
    "\n",
    "amazon['review_clean'] = amazon['review'].apply(remove_punctuation)\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract Sentiments\n",
    "\n",
    "We will ignore all reviews with rating = 3, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  \n",
       "1  it came early and was not disappointed i love ...  \n",
       "2  Very soft and comfortable and warmer than it l...  \n",
       "3  This is a product well worth the purchase  I h...  \n",
       "4  All of my kids have cried nonstop when I tried...  \n",
       "5  When the Binky Fairy came to our house we didn...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = amazon[amazon['rating'] != 3]\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label. A good way is to create an anonymous function that converts a rating into a class label and then apply that function to every element in the rating column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "5  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \\\n",
       "1  it came early and was not disappointed. i love...       5   \n",
       "2  Very soft and comfortable and warmer than it l...       5   \n",
       "3  This is a product well worth the purchase.  I ...       5   \n",
       "4  All of my kids have cried non-stop when I trie...       5   \n",
       "5  When the Binky Fairy came to our house, we did...       5   \n",
       "\n",
       "                                        review_clean  sentiment  \n",
       "1  it came early and was not disappointed i love ...          1  \n",
       "2  Very soft and comfortable and warmer than it l...          1  \n",
       "3  This is a product well worth the purchase  I h...          1  \n",
       "4  All of my kids have cried nonstop when I tried...          1  \n",
       "5  When the Binky Fairy came to our house we didn...          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon['sentiment'] = amazon['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "amazon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test sets\n",
    "\n",
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. If you are using SFrame, make sure to use seed=1 so that you get the same result as everyone else does. (This way, you will get the right numbers for the quiz.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_data_index = json.loads(open('module-2-assignment-train-idx.json').read())\n",
    "test_data_index = json.loads(open('module-2-assignment-test-idx.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = amazon.iloc[train_data_index]\n",
    "test_data = amazon.iloc[test_data_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "  *  Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "  *  Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "  *  Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "  *  Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix.\n",
    "\n",
    "The following cell uses CountVectorizer in scikit-learn. Notice the token_pattern argument in the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data.\n",
    "\n",
    "Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model.\n",
    "\n",
    "There should be over 100,000 coefficients in this sentiment_model. Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (>= 0, which is actually nonnegative) coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sentiment_model = LogisticRegression().fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "How many weights are greater than or equal to 0? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of positive weights:  87151\n",
      "Num of negative weights:  34561\n"
     ]
    }
   ],
   "source": [
    "weights = sentiment_model.coef_\n",
    "num_positive_weights = (weights >= 0).sum()\n",
    "num_negative_weights = (weights < 0).sum()\n",
    "\n",
    "print(\"Num of positive weights: \", num_positive_weights)\n",
    "print(\"Num of negative weights: \", num_negative_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the test data. In this section, we will explore this in the context of 3 data points in the test data. Take the 11th, 12th, and 13th data points in the test data and save them to sample_test_data. The following cell extracts the three data points from the SFrame test_data and print their content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Wall Decor Removable Decal Sticker - Colorful ...</td>\n",
       "      <td>Would not purchase again or recommend. The dec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Would not purchase again or recommend The deca...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>New Style Trailing Cherry Blossom Tree Decal R...</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>1</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "59                          Our Baby Girl Memory Book   \n",
       "71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
       "91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "59  Absolutely love it and all of the Scripture in...       5   \n",
       "71  Would not purchase again or recommend. The dec...       2   \n",
       "91  Was so excited to get this product for my baby...       1   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "59  Absolutely love it and all of the Scripture in...          1  \n",
       "71  Would not purchase again or recommend The deca...         -1  \n",
       "91  Was so excited to get this product for my baby...         -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the sample_test_data. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what the next row of the sample_test_data looks like. As we could guess from the rating (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[1]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a class prediction for the sample_test_data. The sentiment_model should predict +1 if the sentiment is positive and -1 if the sentiment is negative. Recall from the lecture that the score (sometimes called margin) for the logistic regression model is defined as:\n",
    "\n",
    "$score_{i}=w_{T} * h(x_{i})$\n",
    "\n",
    "where h(xi) represents the features for data point i. We will write some code to obtain the scores. For each row, the score (or margin) is a number in the range (-inf, inf). Use a pre-built function in your tool to calculate the score of each data point in sample_test_data. In scikit-learn, you can call the decision_function() function.\n",
    "\n",
    "Hint: You'd probably need to convert sample_test_data into the sparse matrix format first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.60193782,  -3.1693431 , -10.42378132])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_test = sentiment_model.decision_function(test_matrix)\n",
    "score_sample_test = score_test[10:13]\n",
    "score_sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.60193782,  -3.1693431 , -10.42378132])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "score_sample_test_new = sentiment_model.decision_function(sample_test_matrix)\n",
    "score_sample_test_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciting Sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$y^i = +1 if w⊺h(xi)>0 −1 if w⊺h(xi)≤0$\n",
    "\n",
    "Using scores, write code to calculate predicted labels for sample_test_data.\n",
    "\n",
    "Checkpoint: Make sure your class predictions match with the ones obtained from sentiment_model. The logistic regression classifier in scikit-learn comes with the predict function for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "\n",
    "$P(yi=+1|xi,w)=1/(1+exp(−w⊺h(x_i)))$\n",
    "\n",
    "Using the scores calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range [0, 1].\n",
    "\n",
    "Checkpoint: Make sure your probability predictions match the ones obtained from sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.67713366e-03,   9.96322866e-01],\n",
       "       [  9.59664165e-01,   4.03358355e-02],\n",
       "       [  9.99970284e-01,   2.97164132e-05]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sample_test = sentiment_model.predict_proba(sample_test_matrix)\n",
    "prob_sample_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Of the three data points in sample_test_data, which one has the lowest probability of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.96322866e-01,   4.03358355e-02,   2.97164132e-05])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_sample_test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most positive (and negative) review\n",
    "\n",
    "We now turn to examining the full test dataset, test_data, and use sklearn.linear_model.LogisticRegression to form predictions on all of the test data points.\n",
    "\n",
    "Using the sentiment_model, find the 20 reviews in the entire test_data with the highest probability of being classified as a positive review. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "\n",
    "   * Make probability predictions on test_data using the sentiment_model.\n",
    "   * Sort the data according to those predictions and pick the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiangwennorge/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "test_data['prediction_probability'] = sentiment_model.predict_proba(test_matrix)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119182</th>\n",
       "      <td>Roan Rocco Classic Pram Stroller 2-in-1 with B...</td>\n",
       "      <td>Great Pram Rocco!!!!!!I bought this pram from ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Great Pram RoccoI bought this pram from Europe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97325</th>\n",
       "      <td>Freemie Hands-Free Concealable Breast Pump Col...</td>\n",
       "      <td>I absolutely love this product.  I work as a C...</td>\n",
       "      <td>5</td>\n",
       "      <td>I absolutely love this product  I work as a Cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133651</th>\n",
       "      <td>Britax 2012 B-Agile Stroller, Red</td>\n",
       "      <td>[I got this stroller for my daughter prior to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>I got this stroller for my daughter prior to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114796</th>\n",
       "      <td>Fisher-Price Cradle 'N Swing,  My Little Snuga...</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>5</td>\n",
       "      <td>My husband and I cannot state enough how much ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80155</th>\n",
       "      <td>Simple Wishes Hands-Free Breastpump Bra, Pink,...</td>\n",
       "      <td>I just tried this hands free breastpump bra, a...</td>\n",
       "      <td>5</td>\n",
       "      <td>I just tried this hands free breastpump bra an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "119182  Roan Rocco Classic Pram Stroller 2-in-1 with B...   \n",
       "97325   Freemie Hands-Free Concealable Breast Pump Col...   \n",
       "133651                  Britax 2012 B-Agile Stroller, Red   \n",
       "114796  Fisher-Price Cradle 'N Swing,  My Little Snuga...   \n",
       "80155   Simple Wishes Hands-Free Breastpump Bra, Pink,...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "119182  Great Pram Rocco!!!!!!I bought this pram from ...       5   \n",
       "97325   I absolutely love this product.  I work as a C...       5   \n",
       "133651  [I got this stroller for my daughter prior to ...       4   \n",
       "114796  My husband and I cannot state enough how much ...       5   \n",
       "80155   I just tried this hands free breastpump bra, a...       5   \n",
       "\n",
       "                                             review_clean  sentiment  \\\n",
       "119182  Great Pram RoccoI bought this pram from Europe...          1   \n",
       "97325   I absolutely love this product  I work as a Cu...          1   \n",
       "133651  I got this stroller for my daughter prior to t...          1   \n",
       "114796  My husband and I cannot state enough how much ...          1   \n",
       "80155   I just tried this hands free breastpump bra an...          1   \n",
       "\n",
       "        prediction_probability  \n",
       "119182                     1.0  \n",
       "97325                      1.0  \n",
       "133651                     1.0  \n",
       "114796                     1.0  \n",
       "80155                      1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_positive_review_test_data = test_data.sort_values(by = 'prediction_probability', ascending = False)\n",
    "most_positive_review_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Which of the following products are represented in the 20 most positive reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119182    Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
       "97325     Freemie Hands-Free Concealable Breast Pump Col...\n",
       "133651                    Britax 2012 B-Agile Stroller, Red\n",
       "114796    Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
       "80155     Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
       "22586        Britax Decathlon Convertible Car Seat, Tiffany\n",
       "180646        Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
       "50315            P'Kolino Silly Soft Seating in Tias, Green\n",
       "147949    Baby Jogger City Mini GT Single Stroller, Shad...\n",
       "52631     Evenflo X Sport Plus Convenience Stroller - Ch...\n",
       "168081    Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
       "66059          Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
       "137034           Graco Pack 'n Play Element Playard - Flint\n",
       "100166    Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
       "140816           Diono RadianRXT Convertible Car Seat, Plum\n",
       "87017       Baby Einstein Around The World Discovery Center\n",
       "168697    Graco FastAction Fold Jogger Click Connect Str...\n",
       "182089    Summer Infant Wide View Digital Color Video Mo...\n",
       "165593    Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
       "147996    Baby Jogger City Mini GT Double Stroller, Shad...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_positive_review_test_data.head(20)['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Which of the following products are represented in the 20 most negative reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16042           Fisher-Price Ocean Wonders Aquarium Bouncer\n",
       "120209    Levana Safe N'See Digital Video Baby Monitor w...\n",
       "77072        Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
       "48694     Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
       "155287    VTech Communications Safe &amp; Sounds Full Co...\n",
       "94560     The First Years True Choice P400 Premium Digit...\n",
       "53207                   Safety 1st High-Def Digital Monitor\n",
       "81332                 Cloth Diaper Sprayer--styles may vary\n",
       "10677                     Philips AVENT Newborn Starter Set\n",
       "113995    Motorola Digital Video Baby Monitor with Room ...\n",
       "59546                Ellaroo Mei Tai Baby Carrier - Hershey\n",
       "9915           Cosco Alpha Omega Elite Convertible Car Seat\n",
       "40079     Chicco Cortina KeyFit 30 Travel System in Adve...\n",
       "172090    Belkin WeMo Wi-Fi Baby Monitor for Apple iPhon...\n",
       "75994            Peg-Perego Tatamia High Chair, White Latte\n",
       "149987                     NUK Cook-n-Blend Baby Food Maker\n",
       "154878    VTech Communications Safe &amp; Sound Digital ...\n",
       "1116                  Safety 1st Deluxe 4-in-1 Bath Station\n",
       "31741                Regalo My Cot Portable Bed, Royal Blue\n",
       "83234         Thirsties Hemp Inserts 2 Pack, Small 6-18 Lbs\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_negative_review_test_data = test_data.sort_values(by = 'prediction_probability', ascending = True)\n",
    "most_negative_review_test_data.head(20)['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "accuracy=# correctly classified examples / # total examples\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    " *   Step 1: Use the sentiment_model to compute class predictions.\n",
    " *   Step 2: Count the number of data points when the predicted class labels match the ground truth labels.\n",
    " *   Step 3: Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiangwennorge/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>4</td>\n",
       "      <td>This has been an easy way for my nanny to reco...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.784511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Baby Tracker&amp;reg; - Daily Childcare Journal, S...</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>4</td>\n",
       "      <td>I love this journal and our nanny uses it ever...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nature's Lullabies First Year Sticker Calendar</td>\n",
       "      <td>I love this little calender, you can keep trac...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this little calender you can keep track...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had a hard time finding a second year calend...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>One of babys first and favorite books and it i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "9   Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "10  Baby Tracker&reg; - Daily Childcare Journal, S...   \n",
       "16     Nature's Lullabies First Year Sticker Calendar   \n",
       "20    Nature's Lullabies Second Year Sticker Calendar   \n",
       "28                        Lamaze Peekaboo, I Love You   \n",
       "\n",
       "                                               review  rating  \\\n",
       "9   This has been an easy way for my nanny to reco...       4   \n",
       "10  I love this journal and our nanny uses it ever...       4   \n",
       "16  I love this little calender, you can keep trac...       5   \n",
       "20  I had a hard time finding a second year calend...       5   \n",
       "28  One of baby's first and favorite books, and it...       4   \n",
       "\n",
       "                                         review_clean  sentiment  \\\n",
       "9   This has been an easy way for my nanny to reco...          1   \n",
       "10  I love this journal and our nanny uses it ever...          1   \n",
       "16  I love this little calender you can keep track...          1   \n",
       "20  I had a hard time finding a second year calend...          1   \n",
       "28  One of babys first and favorite books and it i...          1   \n",
       "\n",
       "    prediction_probability  prediction  \n",
       "9                 0.784511           1  \n",
       "10                0.999999           1  \n",
       "16                0.933217           1  \n",
       "20                0.999979           1  \n",
       "28                0.980231           1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['prediction'] = sentiment_model.predict(test_matrix)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.932295416367\n"
     ]
    }
   ],
   "source": [
    "test_label = test_data['sentiment'] == test_data['prediction']\n",
    "total_true = sum(test_label)\n",
    "accuracy_score = total_true/len(test_label)\n",
    "print(\"Accuracy score: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "What is the accuracy of the sentiment_model on the test_data? Round your answer to 2 decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.932295416367\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_predict = sentiment_model.predict(test_matrix)\n",
    "\n",
    "print(\"Accuracy score: \", metrics.accuracy_score(y_predict, test_data['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "Does a higher accuracy value on the training_data always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No, higher accuracy on training data does not necessarily imply that the classifier is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subet of words that occur in the reviews. For this assignment, we selected 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression model on a subset of data\n",
    "\n",
    "Now build a logistic regression classifier with train_matrix_word_subset as features and sentiment as the target. Call this model simple_model.\n",
    "\n",
    "Let us inspect the weights (coefficients) of the simple_model. First, build a table to store (word, coefficient) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = LogisticRegression().fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "Consider the coefficients of simple_model. There should be 21 of them, an intercept term + one for each word in significant_words.\n",
    "\n",
    "How many of the 20 coefficients (corresponding to the 20 significant_words and excluding the intercept term) are positive for the simple_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(simple_model.coef_ >= 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "Are the positive words in the simple_model also positive words in the sentiment_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36368976,  0.94399959,  1.19253827,  0.08551278,  0.52018576,\n",
       "         1.50981248,  1.67307389,  0.50376046,  0.19090857,  0.05885467,\n",
       "        -1.65157634, -0.20956286, -0.51137963, -2.03369861, -2.34829822,\n",
       "        -0.62116877, -0.32055624, -0.89803074, -0.36216674, -2.10933109]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_words = [word for word in vectorizer.vocabulary_.keys()]\n",
    "significant_words_index = [sentiment_words.index(word) for word in significant_words]\n",
    "sentiment_weight = [sentiment_model.coef_[0][word_index] for word_index in significant_words_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight on sentiment_model</th>\n",
       "      <th>weight on simple_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>2.129163e-01</td>\n",
       "      <td>0.190909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broke</th>\n",
       "      <td>-7.191992e-01</td>\n",
       "      <td>-1.651576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>5.519557e-02</td>\n",
       "      <td>0.058855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointed</th>\n",
       "      <td>2.854324e-03</td>\n",
       "      <td>-2.348298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>-5.468800e-03</td>\n",
       "      <td>1.192538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>7.929719e-02</td>\n",
       "      <td>-0.511380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>6.483661e-02</td>\n",
       "      <td>0.944000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>less</th>\n",
       "      <td>4.175778e-02</td>\n",
       "      <td>-0.209563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>-3.146887e-01</td>\n",
       "      <td>0.520186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>2.670837e-01</td>\n",
       "      <td>1.363690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loves</th>\n",
       "      <td>1.043761e-02</td>\n",
       "      <td>1.673074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>5.781430e-04</td>\n",
       "      <td>-0.898031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>8.179701e-03</td>\n",
       "      <td>0.085513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>-6.860067e-01</td>\n",
       "      <td>1.509812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>2.334292e-02</td>\n",
       "      <td>-0.320556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>1.987394e-01</td>\n",
       "      <td>-2.109331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>5.762655e-03</td>\n",
       "      <td>-2.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>6.160998e-07</td>\n",
       "      <td>0.503760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>1.079507e-05</td>\n",
       "      <td>-0.621169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>2.199556e-01</td>\n",
       "      <td>-0.362167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              weight on sentiment_model  weight on simple_model\n",
       "able                       2.129163e-01                0.190909\n",
       "broke                     -7.191992e-01               -1.651576\n",
       "car                        5.519557e-02                0.058855\n",
       "disappointed               2.854324e-03               -2.348298\n",
       "easy                      -5.468800e-03                1.192538\n",
       "even                       7.929719e-02               -0.511380\n",
       "great                      6.483661e-02                0.944000\n",
       "less                       4.175778e-02               -0.209563\n",
       "little                    -3.146887e-01                0.520186\n",
       "love                       2.670837e-01                1.363690\n",
       "loves                      1.043761e-02                1.673074\n",
       "money                      5.781430e-04               -0.898031\n",
       "old                        8.179701e-03                0.085513\n",
       "perfect                   -6.860067e-01                1.509812\n",
       "product                    2.334292e-02               -0.320556\n",
       "return                     1.987394e-01               -2.109331\n",
       "waste                      5.762655e-03               -2.033699\n",
       "well                       6.160998e-07                0.503760\n",
       "work                       1.079507e-05               -0.621169\n",
       "would                      2.199556e-01               -0.362167"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict = {word:weight for (word, weight) in zip(significant_words, sentiment_weight)}\n",
    "simple_dict = {word:weight for (word, weight) in zip(significant_words, simple_model.coef_[0])}\n",
    "\n",
    "word_compare = pd.DataFrame({\"weight on sentiment_model\": sentiment_dict, \"weight on simple_model\": simple_dict})\n",
    "word_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing models\n",
    "\n",
    "We will now compare the accuracy of the sentiment_model and the simple_model.\n",
    "\n",
    "First, compute the classification accuracy of the sentiment_model on the train_data.\n",
    "\n",
    "Now, compute the classification accuracy of the simple_model on the train_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for sentiment_model on the train_data:  0.96849703184\n",
      "Accuracy score for simple_model on the train_data:  0.866822570007\n"
     ]
    }
   ],
   "source": [
    "y_predict_sentiment_model = sentiment_model.predict(train_matrix)\n",
    "y_predict_simple_model = simple_model.predict(train_matrix_word_subset)\n",
    "\n",
    "print(\"Accuracy score for sentiment_model on the train_data: \", metrics.accuracy_score(y_predict_sentiment_model, train_data['sentiment']))\n",
    "print(\"Accuracy score for simple_model on the train_data: \", metrics.accuracy_score(y_predict_simple_model, train_data['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "Which model (sentiment_model or simple_model) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sentiment_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "Which model (sentiment_model or simple_model) has higher accuracy on the TEST set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for sentiment_model on the test data:  0.932295416367\n",
      "Accuracy score for simple model on the test data:  0.869360451164\n"
     ]
    }
   ],
   "source": [
    "y_predict_sentiment_model_test = sentiment_model.predict(test_matrix)\n",
    "y_predict_simple_model_test = simple_model.predict(test_matrix_word_subset)\n",
    "\n",
    "print(\"Accuracy score for sentiment_model on the test data: \", metrics.accuracy_score(y_predict_sentiment_model_test, test_data['sentiment']))\n",
    "print(\"Accuracy score for simple model on the test data: \", metrics.accuracy_score(y_predict_simple_model_test, test_data['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the majority class classifier as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    28095\n",
       "-1     5241\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_majority_class = np.ones((len(test_data['sentiment']), 1), dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 11\n",
    "Enter the accuracy of the majority class classifier model on the test_data. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for majority class classifier model on the test data:  0.842782577394\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score for majority class classifier model on the test data: \", metrics.accuracy_score(y_predict_majority_class, test_data['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 12\n",
    "Is the sentiment_model definitely better than the majority class classifier (the baseline)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
